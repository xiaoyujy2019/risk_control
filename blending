# -*- coding: utf-8 -*-
"""
Created on Sat Nov  7 14:03:01 2019
@author: XiaoYu
"""
import numpy as np
import pandas as pd
from heamy.dataset import Dataset
from heamy.estimator import Regressor, Classifier
from heamy.pipeline import ModelsPipeline
import xgboost as xgb
import lightgbm as lgb
from sklearn.metrics import roc_auc_score
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor
from sklearn.model_selection import KFold
from mlxtend.regressor import StackingRegressor

def xgb_feature(X_train, y_train, X_test, y_test=None):
    model = xgb.XGBClassifier().fit(X_train, y_train)  
    pre = model.predict_proba(X_test)[:,1]
    return pre

def rf_model(X_train, y_train, X_test, y_test=None):
    model = RandomForestClassifier(min_samples_leaf=4,min_samples_split=10,max_depth=5,random_state=30,n_estimators=130,max_features='sqrt' ,oob_score=True).fit(X_train,y_train)
    pre = model.predict_proba(X_test)[:,1]
    return pre

def et_model(X_train, y_train, X_test, y_test=None):
    model = ExtraTreesClassifier(max_features = 'log2', n_estimators = 1000 , n_jobs = -1).fit(X_train,y_train)
    return model.predict_proba(X_test)[:,1]

def lgb_feature(X_train, y_train, X_test, y_test=None):
    model = lgb.LGBMClassifier(boosting_type='gbdt',  min_data_in_leaf=5, max_bin=200, num_leaves=25, learning_rate=0.01).fit(X_train, y_train) 
    pre = model.predict_proba(X_test)[:,1]
    return pre
def gbdt_model(X_train, y_train, X_test, y_test=None):

    model = GradientBoostingClassifier(learning_rate = 0.02, max_features = 0.7, n_estimators = 100 , max_depth = 5).fit(X_train,y_train)
    pre = model.predict_proba(X_test)[:,1]
    return pre
                      
def logistic_model(X_train, y_train, X_test, y_test=None):
    model = LogisticRegression(penalty = 'l2').fit(X_train,y_train)
    return model.predict_proba(X_test)[:,1]

#建模训练
VAILD = False
if __name__ == '__main__':
    if VAILD == False:
        train_data = pd.read_csv('C:\\Users\\Administrator\\Desktop\\handled\\newtrain.csv',engine = 'python')
        test_data = pd.read_csv('C:\\Users\\Administrator\\Desktop\\handled\\newtest.csv',engine = 'python')
        target  = pd.read_csv('H:\\train_target.csv')    
        data1= Dataset(X_train=train_data,y_train=target['target'],X_test=test_data,y_test=None,use_cache=False)
        print (">>>开始构建pipeline：ModelsPipeline(model_xgb, model_lgb,model_rf)")
        model_xgb = Regressor(dataset=data1, estimator=xgb_feature,name='xgb',use_cache=False)
        model_gbdt = Regressor(dataset=data1, estimator=gbdt_model,name='gbdt',use_cache=False)
        model_lgb = Regressor(dataset=data1, estimator=lgb_feature,name='lgb',use_cache=False)
        model_rf = Regressor(dataset=data1, estimator=rf_model,name='rf',use_cache=False)
          
        pipeline = ModelsPipeline(model_xgb, model_lgb,model_rf)
        print (">>>开始训练pipeline：pipeline.blend(proportion=0.1,seed=111)")
        stack_ds = pipeline.blend( proportion=0.2,seed=111)      
        print ("stack_ds: ", stack_ds)
        print (">>>开始训练Regressor：Regressor(dataset=stack_ds, estimator=LinearRegression,parameters={'fit_intercept': False})")
        stacker = Regressor(dataset=stack_ds, estimator=LinearRegression,parameters={'fit_intercept': False})
        print (">>>开始预测：")
        result = stacker.predict()
        print(result)      
        
#保存数据        
id = list(range(132030,155591))
c ={ "id" : id, "target" : result  }
re = pd.DataFrame(c)
re.to_csv('C:\\Users\\Administrator\\Desktop\\blending1107.csv' )
print(re)
